---practical3---perform the data classification algorithm using R/python

rainfall.timeseries<-c(799,1172.5,345.7,987.4,2334.4,243.5,877.4,199.2,544.3,388.1,699.1)
rainfall.timeseries<-ts(rainfall,start = c(2012,1),frequency=12)
print(rainfall.timeseries)
png("rainfall.png")
plot(rainfall.timeseries)
dev.off()
plot(rainfall.timeseries)



---practical4---perform the data clustering using clustering algorithm using R/python

newiris<-iris
newiris$Species<-NULL
(kc<-kmeans(newiris,3))
table(iris$Species,kc$cluster)
plot(newiris[c("Sepal.Length","Sepal.Width")],col=kc$cluster)



---practical5--- Perform the Linear regression on the given data warehouse data using R/Python

x <- c(151, 174, 138, 186, 128, 136, 179, 163, 152, 131) 
y <- c(63, 81, 56, 91, 47, 57, 76, 72, 62, 48)
relation <- lm(y~x) 
print(relation) 
print(summary(relation))
a <- data.frame(x = 170) 
result <- predict(relation,a)  
print(result)
png(file = "linearregression.png")
plot(y,x,col = "blue",main = "Height & Weight Regression", abline(lm(x~y)),cex = 1.3,pch = 16,xlab = 
       "Weight in Kg",ylab = "Height in cm")
dev.off()
plot(y,x,col = "blue",main = "Height & Weight Regression", abline(lm(x~y)),cex = 1.3,pch = 16,xlab = 
       "Weight in Kg",ylab ="Height in cm")



---practical6---perform the logistic regression on the given data warehouse data using R/python

library(datasets)
ir_data<-iris
head(ir_data)
str(ir_data)
levels(ir_data$species)
sum(is.na(ir_data))
ir_data<-ir_data[1:100,]
set.seed(100)
samp<-sample(1:100,80) 
ir_test<-ir_data[samp,]
ir_ctrl<-ir_data[-samp,]
install.packages("ggplot2")
library(ggplot2)
install.packages("GGally")
library(GGally)
ggpairs(ir_test)
y<-ir_test$Species; 
x<-ir_test$Sepal.Length 
glfit<-glm(y~x,family='binomial')
summary(glfit)
newdata<-data.frame(x=ir_ctrl$Sepal.Length)
predicted_val<- predict(glfit, newdata, type= "response")
prediction<-data.frame(ir_ctrl$Sepal.Length,ir_ctrl$Species,predicted_val)
prediction<-qplot(prediction [, 1],round(prediction[,3]),col=prediction[,2],xlab= 'Sepal Length', ylab='prediction using Logistic Reg.')



---practical7---write a python program to read data from a CSV file, perform simple data analysis,& generate basic insights(use pandas is a python library)

import pandas as pd
file_path = "C:\\Users\\DELL\\Downloads\\customers-100.csv"
df = pd.read_csv(file_path)
print("\n First 5 rows of the dataset:")
print(df.head()) # Show the first 5 rows
print("\n Dataset Summary:")
print(df.info())
print("\n Basic Statistics:")
print(df.describe())
print("\n Missing Values in Each Column:")
print(df.isnull().sum())
print("\n Column Names:")
print(df.columns)



---practical8---A) perform data visualization using python on any sales data B) perform data visualization using powerBI on any sales data

import pandas as pd
from matplotlib import pyplot as plt
plt.rcParams["figure.figsize"]=[8.00,4.50]
plt.rcParams["figure.autolayout"]=True
columns=["Item_name","Qty_sold"]
df=pd.read_csv("C:\\Users\\DELL\\OneDrive\\Desktop\\sample.csv",usecols=columns)
print("Contents in csv file:",df)
plt.plot(df.Item_name,df.Qty_sold)
plt.show()
